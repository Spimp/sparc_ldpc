{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPARC AMP Example\n",
    "\n",
    "This notebook contains a complete worked example of a SPARC AMP encoder/decoder using Hadamard design matrices and various power allocation strategies.\n",
    "\n",
    "For full details of the algorithm please see our paper _\"Capacity-achieving Sparse Superposition Codes via Approximate Message Passing Decoding_\": https://arxiv.org/abs/1501.05892\n",
    "\n",
    "For further optimisation details please see the follow up paper _\"Optimising the Finite-Length Performance of AMP-decoded Sparse Regression Codes\"_.\n",
    "\n",
    "This notebook is Copyright 2016, 2017 Adam Greig."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "We need numpy and ideally an accelerated Hadamard transform written in C, available to install as the `pyfht` library (try `sudo pip install pyfht` or similar for your Python package installation system).\n",
    "\n",
    "If `pyfht` is not available we can fall back to a Python version, but beware it is a great deal slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import log\n",
    "\n",
    "try:\n",
    "    from pyfht import fht_inplace\n",
    "except ImportError:\n",
    "    import warnings\n",
    "    warnings.warn(\"Using very slow Python version of fht, please install pyfht\")\n",
    "    def fht_inplace(x):\n",
    "        N = len(x)\n",
    "        i = N>>1\n",
    "        while i:\n",
    "            for k in range(0, N, 2*i):\n",
    "                for j in range(k, i+k):\n",
    "                    ij = i|j\n",
    "                    temp = x[j]\n",
    "                    x[j] += x[ij]\n",
    "                    x[ij] = temp - x[ij]\n",
    "            i = i >> 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast Hadamard Transforms\n",
    "\n",
    "These functions use the in-place Hadamard transform to emulate matrix operations on a random $\\pm1$ matrix of any size smaller than the underlying Hadamard matrix. We then also combine $L$ such operations for efficiency when using very wide matrices, typical for SPARC dictionaries.\n",
    "\n",
    "None of this code is particularly relevant to the actual SPARC-AMP decoder, so feel free to skip over it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_fht(n, m, seed=0, ordering=None):\n",
    "    \"\"\"\n",
    "    Returns functions to compute the sub-sampled Walsh-Hadamard transform,\n",
    "    i.e., operating with a wide rectangular matrix of random +/-1 entries.\n",
    "\n",
    "    n: number of rows\n",
    "    m: number of columns\n",
    "\n",
    "    It is most efficient (but not required) for max(m+1,n+1) to be a power of 2.\n",
    "\n",
    "    seed: determines choice of random matrix\n",
    "    ordering: optional n-long array of row indices in [1, max(m,n)] to\n",
    "              implement subsampling; generated by seed if not specified,\n",
    "              but may be given to speed up subsequent runs on the same matrix.\n",
    "\n",
    "    Returns (Ax, Ay, ordering):\n",
    "        Ax(x): computes A.x (of length n), with x having length m\n",
    "        Ay(y): computes A'.y (of length m), with y having length n\n",
    "        ordering: the ordering in use, which may have been generated from seed\n",
    "    \"\"\"\n",
    "    assert n > 0, \"n must be positive\"\n",
    "    assert m > 0, \"m must be positive\"\n",
    "    w = 2**int(np.ceil(np.log2(max(m+1, n+1))))\n",
    "\n",
    "    if ordering is not None:\n",
    "        assert ordering.shape == (n,)\n",
    "    else:\n",
    "        rng = np.random.RandomState(seed)\n",
    "        idxs = np.arange(1, w, dtype=np.uint32)\n",
    "        rng.shuffle(idxs)\n",
    "        ordering = idxs[:n]\n",
    "\n",
    "    def Ax(x):\n",
    "        assert x.size == m, \"x must be m long\"\n",
    "        y = np.zeros(w)\n",
    "        y[w-m:] = x.reshape(m)\n",
    "        fht_inplace(y)\n",
    "        return y[ordering]\n",
    "\n",
    "    def Ay(y):\n",
    "        assert y.size == n, \"input must be n long\"\n",
    "        x = np.zeros(w)\n",
    "        x.flat[ordering] = y\n",
    "        fht_inplace(x)\n",
    "        return x[w-m:]\n",
    "\n",
    "    return Ax, Ay, ordering\n",
    "\n",
    "def block_sub_fht(n, m, l, seed=0, ordering=None):\n",
    "    \"\"\"\n",
    "    As `sub_fht`, but computes in `l` blocks of size `n` by `m`, potentially\n",
    "    offering substantial speed improvements.\n",
    "\n",
    "    n: number of rows\n",
    "    m: number of columns per block\n",
    "    l: number of blocks\n",
    "\n",
    "    It is most efficient (though not required) when max(m+1,n+1) is a power of 2.\n",
    "\n",
    "    seed: determines choice of random matrix\n",
    "    ordering: optional (l, n) shaped array of row indices in [1, max(m, n)] to\n",
    "              implement subsampling; generated by seed if not specified, but\n",
    "              may be given to speed up subsequent runs on the same matrix.\n",
    "\n",
    "    Returns (Ax, Ay, ordering):\n",
    "        Ax(x): computes A.x (of length n), with x having length l*m\n",
    "        Ay(y): computes A'.y (of length l*m), with y having length n\n",
    "        ordering: the ordering in use, which may have been generated from seed\n",
    "    \"\"\"\n",
    "    assert n > 0, \"n must be positive\"\n",
    "    assert m > 0, \"m must be positive\"\n",
    "    assert l > 0, \"l must be positive\"\n",
    "\n",
    "    if ordering is not None:\n",
    "        assert ordering.shape == (l, n)\n",
    "    else:\n",
    "        w = 2**int(np.ceil(np.log2(max(m+1, n+1))))\n",
    "        rng = np.random.RandomState(seed)\n",
    "        ordering = np.empty((l, n), dtype=np.uint32)\n",
    "        idxs = np.arange(1, w, dtype=np.uint32)\n",
    "        for ll in range(l):\n",
    "            rng.shuffle(idxs)\n",
    "            ordering[ll] = idxs[:n]\n",
    "        \n",
    "\n",
    "    def Ax(x):\n",
    "        assert x.size == l*m\n",
    "        out = np.zeros(n)\n",
    "        for ll in range(l):\n",
    "            ax, ay, _ = sub_fht(n, m, ordering=ordering[ll])\n",
    "            out += ax(x[ll*m:(ll+1)*m])\n",
    "        return out\n",
    "\n",
    "    def Ay(y):\n",
    "        assert y.size == n\n",
    "        out = np.empty(l*m)\n",
    "        for ll in range(l):\n",
    "            ax, ay, _ = sub_fht(n, m, ordering=ordering[ll])\n",
    "            out[ll*m:(ll+1)*m] = ay(y)\n",
    "        return out\n",
    "\n",
    "    return Ax, Ay, ordering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPARC Dictionary\n",
    "\n",
    "We use the `block_sub_fht` which computes the equivalent of $A\\beta$ by using $L$ separate $M\\times M$ Hadamard matrices. However we want each entry to be divided by $\\sqrt{n}$ to get the right variance, and we need to do a reshape on the output to get column vectors, so we'll wrap those operations here.\n",
    "\n",
    "Returns two functions `Ab` and `Az` which compute $A\\beta$ and $A^Tz$ respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparc_transforms(L, M, n):\n",
    "    Ax, Ay, _ = block_sub_fht(n, M, L, ordering=None)\n",
    "    def Ab(b):\n",
    "        return Ax(b).reshape(-1, 1) / np.sqrt(n)\n",
    "    def Az(z):\n",
    "        return Ay(z).reshape(-1, 1) / np.sqrt(n)\n",
    "    return Ab, Az"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power Allocation\n",
    "\n",
    "There are multiple choices for power allocation algorithm. Here we give the \"standard exponential\" allocation used for the capacity-achieving proof; a similar exponential with parameterised steepness which is flattened after some point; and a newer iterative allocation which aims to allocate just sufficient power for blocks of sections to decode successively. You can select which is used by altering the function called from `amp_sim` below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original\n",
    "This power allocation is:\n",
    "$P_\\ell \\propto 2^{-2\\mathcal{C}\\ell/L}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pa_original(L, C, P):\n",
    "    #Is it wrong that the below contains an a?\n",
    "    pa = 2**(-2 * a * C * np.arange(L) / L)\n",
    "    pa /= pa.sum() / P\n",
    "    return pa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameterised\n",
    "\n",
    "We generate a power allocation parameterised by $a$ and $f$ which set the steepness and the flattening point respectively.\n",
    "\n",
    "The power allocation follows $P_\\ell \\propto 2^{-2a\\mathcal{C}\\ell/L}$ up to $fL$, and then is flat after that point, and scaled so that the sum power is $P$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pa_parameterised(L, C, P, a, f):\n",
    "    pa = 2**(-2 * a * C * np.arange(L) / L)\n",
    "    pa[int(f*L):] = pa[int(f*L)]\n",
    "    pa /= pa.sum() / P\n",
    "    return pa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative\n",
    "\n",
    "We split the sections into $B$ blocks of $L/B$ sections each, where each section in a block has the same power. Then each block is assigned just enough power to meet the requirement $P_\\ell > 2(\\ln 2)R\\tau_t^2 / L$. In practice the rate $R_\\text{PA}$ used here is set independently from the actual codeword rate to allow altering the power allocation. When the total unallocated power is sufficient to give all remaining sections the same power, we do that to complete the allocation.\n",
    "\n",
    "One modification is to pass $B=L$, so each block contains only one section. This tends to perform better when given sufficient iterations.\n",
    "\n",
    "For further details on this power allocation, see _\"Optimising the Finite-Length Performance of AMP-decoded Sparse Regression Codes\"_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pa_iterative(L, B, σ, P, R_PA):\n",
    "    PA = np.zeros(L)\n",
    "    τ = np.zeros(B)\n",
    "    k = L//B\n",
    "    for b in range(B):\n",
    "        Premain = P - PA.sum()\n",
    "        τ[b] = np.sqrt(σ**2 + Premain)\n",
    "        Pblock = 2 * np.log(2) * (R_PA/L) * τ[b]**2\n",
    "        Pspread = Premain / (L - k*b)\n",
    "        if Pblock > Pspread:\n",
    "            PA[k*b:k*(b+1)] = Pblock\n",
    "        else:\n",
    "            PA[k*b:] = Pspread\n",
    "            break\n",
    "    return PA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AMP\n",
    "This is the actual AMP algorithm. It's a mostly straightforward transcription from the relevant equations, but we regularise the exponential terms to prevent overflow and improve numerical precision.\n",
    "\n",
    "We estimate $\\tau^2$ from $\\mathrm{Var}[z]$ rather than pre-computed constants.\n",
    "If $\\tau^2$ hasn't changed between two iterations, we can stop early.\n",
    "For further details on these optimisations, see _\"Optimising the Finite-Length Performance of AMP-decoded Sparse Regression Codes\"_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amp(y, σ_n, Pl, L, M, T, Ab, Az):\n",
    "    P = np.sum(Pl)\n",
    "    n = y.size\n",
    "    β = np.zeros((L*M, 1))\n",
    "    z = y\n",
    "    last_τ = 0\n",
    "    \n",
    "    for t in range(T):\n",
    "        τ = np.sqrt(np.sum(z**2)/n)\n",
    "        if τ == last_τ:\n",
    "            return β\n",
    "        last_τ = τ\n",
    "        \n",
    "        s = β + Az(z)\n",
    "        rt_n_Pl = np.sqrt(n*Pl).repeat(M).reshape(-1, 1)\n",
    "        u = s * rt_n_Pl / τ**2\n",
    "        max_u = u.max()\n",
    "        exps = np.exp(u - max_u)\n",
    "        sums = exps.reshape(L, M).sum(axis=1).repeat(M).reshape(-1, 1)\n",
    "        β = (rt_n_Pl * exps / sums).reshape(-1, 1)\n",
    "        z = y - Ab(β) + (z/τ**2) * (P - np.sum(β**2) / n)\n",
    "    \n",
    "    return β"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bitwise Posterior Probabilities\n",
    "Calculate bitwise posterior probabilities from section wise posterior probabilities. \n",
    "\n",
    "This function is written by Katie. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bitwise_posterior(β, L, M):\n",
    "    #take in the section posterior probabilities β.\n",
    "    #and the no. sections L and the size of each section M. \n",
    "    assert M%2 == 0 # should this be power of 2?\n",
    "    \n",
    "    #initialise numpy array of zeros for all of the bitwise posteriors\n",
    "    p = np.zeros(int(log(M,2)*L))\n",
    "    #loop through the L sections.\n",
    "    for a in range(L):\n",
    "        β_l = β[a*M:((a+1)*M)]\n",
    "        c = np.sum(β_l) #calculate normalization constant for each section\n",
    "        for logi in range(int(log(M,2))):\n",
    "            b = int((a+1)*log(M,2) - logi - 1)\n",
    "            i = pow(2, logi)\n",
    "            k = i\n",
    "            while k<M:\n",
    "                #note shift in range of j due to βl being an array which is indexed from 0 not 1. \n",
    "                for j in range(k, k+i):\n",
    "                    p[b] = p[b] + β_l[j]/c\n",
    "                k = k + 2*i\n",
    "    return p\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPARC-AMP Simulation\n",
    "Here we perform the actual simulation. The comments inline guide you through what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amp_sim(L, M, σ_n, P, R, T, R_PA):\n",
    "    # Compute the SNR, capacity, and n, from the input parameters\n",
    "    snr = P / σ_n**2\n",
    "    #C = 0.5 * np.log2(1 + snr)\n",
    "    n = int(L*np.log2(M) / R)\n",
    "    \n",
    "    # Generate the power allocation\n",
    "    Pl = pa_iterative(L, L, σ_n, P, R_PA)\n",
    "    \n",
    "    # Generate random message in [0..M)^L\n",
    "    tx_message = np.random.randint(0, M, L).tolist()\n",
    "    \n",
    "    # instead of generating a message like above, generate a random number of bits\n",
    "    \n",
    "    # apply an LDPC code to these bits\n",
    "    \n",
    "    # Then convert this to indices. Ensuring that the output of the LDPC code can be encoded with L sections of size M\n",
    "    \n",
    "    # Generate the SPARC transform functions A.beta and A'.z\n",
    "    Ab, Az = sparc_transforms(L, M, n)\n",
    "    \n",
    "    # Generate our transmitted signal X\n",
    "    β_0 = np.zeros((L*M, 1))\n",
    "    for l in range(L):\n",
    "        β_0[l*M + tx_message[l]] = np.sqrt(n * Pl[l])\n",
    "    x = Ab(β_0)\n",
    "    \n",
    "    # Generate random channel noise and then received signal y\n",
    "    z = np.random.randn(n, 1) * σ_n\n",
    "    y = (x + z).reshape(-1, 1)\n",
    "        \n",
    "    # Run AMP decoding\n",
    "    β = amp(y, σ_n, Pl, L, M, T, Ab, Az).reshape(-1)\n",
    "    # Output the results of just AMP decoding\n",
    "    #The above is the section wise probabilities. I need to convert these to bitwise probabilities. \n",
    "    # Feed the bitwise probabilities into the LDPC decoder\n",
    "    \n",
    "    # Get the output of the LDPC decoder and see if there has been any improvement in error correcting performance. \n",
    "    # Note that for now I am just applying an LDPC code to the entire block. \n",
    "    \n",
    "    #print(bitwise_posterior(β, L, M))\n",
    "    \n",
    "    # Convert decoded beta back to a message\n",
    "    rx_message = []\n",
    "    for l in range(L):\n",
    "        idx = np.argmax(β[l*M:(l+1)*M])\n",
    "        rx_message.append(idx)\n",
    "    \n",
    "    # Compute fraction of sections decoded correctly\n",
    "    correct = np.sum(np.array(rx_message) == np.array(tx_message)) / L\n",
    "    \n",
    "    # Compute BER note: np.sum will be deprecated soon, so look up alternative if this code stops working. \n",
    "    # DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.from_iter(generator)) or the python sum builtin instead.\n",
    "    # If this function starts acting weird, look into the above. Or when I transfer this function to my proper code, try to fix this. \n",
    "    ber = np.sum(bin(a^b).count('1')\n",
    "                 for (a, b) in zip(tx_message, rx_message))/(L*np.log2(M))\n",
    "    \n",
    "    # Compute Eb/N0\n",
    "    EbN0 = 1/(2*R) * (P/σ_n**2)\n",
    "    \n",
    "    return 1-correct\n",
    "    \n",
    "    \"\"\"return {\n",
    "        \"L\": L, \"M\": M, \"sigma_n\": σ_n, \"P\": P, \"R\": R, \"T\": T,\n",
    "        \"snr\": snr, \"C\": C, \"n\": n, \"fc\": correct, \"R_PA\": R_PA,\n",
    "        \"ber\": ber, \"EbN0\": EbN0, \"ser\": 1-correct\n",
    "    }\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a trial run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aa/anaconda2/envs/sparc/lib/python3.5/site-packages/ipykernel_launcher.py:45: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.from_iter(generator)) or the python sum builtin instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 2.0,\n",
       " 'EbN0': 5.357142857142858,\n",
       " 'L': 1024,\n",
       " 'M': 512,\n",
       " 'P': 15.0,\n",
       " 'R': 1.4,\n",
       " 'R_PA': 1.4,\n",
       " 'T': 64,\n",
       " 'ber': 0.0,\n",
       " 'fc': 1.0,\n",
       " 'n': 6582,\n",
       " 'ser': 0.0,\n",
       " 'sigma_n': 1.0,\n",
       " 'snr': 15.0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "amp_sim(1024, 512, 1.0, 15.0, 1.4, 64, 1.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fc` is the fraction of sections decoded correctly - 100% in this case, so no errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate the performance of a plain SPARC (without outer LDPC code). Fix the rate and then slowly increase the snr values from the shannon limit. For a rate R SPARC, the shannon limit SNR is the theoretical minimum possible snr for a rate R. It is given by R = 0.5*log_2(1+snr)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aa/anaconda2/envs/sparc/lib/python3.5/site-packages/ipykernel_launcher.py:46: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.from_iter(generator)) or the python sum builtin instead.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pylab import *\n",
    "# fix rate\n",
    "R = 1\n",
    "\n",
    "σ_n = 1.0\n",
    "# shannon limit on snr \n",
    "snr = 2**(2*R)-1\n",
    "P = snr * σ_n**2\n",
    "# Unsure what values to choose for T and R_PA. Just copied previous example.\n",
    "T = 64\n",
    "R_PA = R\n",
    "\n",
    "# store the error rate for each snr\n",
    "error_rate = []\n",
    "repeats = 50\n",
    "for i in range(3,10):\n",
    "    error = []\n",
    "    for i in range(repeats):\n",
    "        error.append(amp_sim(512, 512, σ_n, P, R, T, R_PA))\n",
    "    aver_error = np.sum(error)\n",
    "    error_rate.append(aver_error/repeats)\n",
    "    \n",
    "plot(range(3,10), error_rate)\n",
    "xlabel('snr')\n",
    "ylabel('Error Rate')\n",
    "show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.7]\n",
      " [0.3]\n",
      " [0.6]\n",
      " [0.4]\n",
      " [0.4]\n",
      " [1.6]\n",
      " [0.4]\n",
      " [0.3]]\n",
      "[0.5        0.35       0.25925926 0.7037037 ]\n"
     ]
    }
   ],
   "source": [
    "#Code to test that the bitwise posterior is working as desired. \n",
    "\n",
    "L = 2\n",
    "M = 4\n",
    "β = np.zeros((L*M, 1))\n",
    "β[0] = 0.7\n",
    "β[1] = 0.3\n",
    "β[2] = 0.6\n",
    "β[3] = 0.4\n",
    "β[4] = 0.4\n",
    "β[5] = 1.6\n",
    "β[6] = 0.4\n",
    "β[7] = 0.3\n",
    "print(β)\n",
    "print(bitwise_posterior(β, L, M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fido\n"
     ]
    }
   ],
   "source": [
    "class Dog:\n",
    "\n",
    "    kind = 'canine'         # class variable shared by all instances\n",
    "\n",
    "    def __init__(self, name, age):\n",
    "        self.name = name \n",
    "        self.age = age \n",
    "\n",
    "d = Dog('Fido', 1)\n",
    "e = Dog('Buddy', 4)\n",
    "d.kind  \n",
    "\n",
    "def printsDog(dogDetails: Dog):\n",
    "    print(dogDetails.name)\n",
    "    \n",
    "printsDog(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amp_ldpc_sim(L, M, σ_n, P, R, T, R_PA, R_LDPC):\n",
    "    # Compute the SNR, capacity, and n, from the input parameters\n",
    "    snr = P / σ_n**2\n",
    "    C = 0.5 * np.log2(1 + snr)\n",
    "    n = int(L*np.log2(M) / R)\n",
    "    \n",
    "    # Generate the power allocation\n",
    "    Pl = pa_iterative(L, L, σ_n, P, R_PA)\n",
    "    \n",
    "    # Generate random message in [0..M)^L\n",
    "    tx_message = np.random.randint(0, M, L).tolist()\n",
    "    \n",
    "    # instead of generating a message like above, generate a random number of bits\n",
    "    \n",
    "    \n",
    "    # apply an LDPC code to these bits\n",
    "    \n",
    "    # Then convert this to indices. Ensuring that the output of the LDPC code can be encoded with L sections of size M\n",
    "    \n",
    "    # Generate the SPARC transform functions A.beta and A'.z\n",
    "    Ab, Az = sparc_transforms(L, M, n)\n",
    "    \n",
    "    # Generate our transmitted signal X\n",
    "    β_0 = np.zeros((L*M, 1))\n",
    "    for l in range(L):\n",
    "        β_0[l*M + tx_message[l]] = np.sqrt(n * Pl[l])\n",
    "    x = Ab(β_0)\n",
    "    \n",
    "    # Generate random channel noise and then received signal y\n",
    "    z = np.random.randn(n, 1) * σ_n\n",
    "    y = (x + z).reshape(-1, 1)\n",
    "        \n",
    "    # Run AMP decoding\n",
    "    β = amp(y, σ_n, Pl, L, M, T, Ab, Az).reshape(-1)\n",
    "    # Output the results of just AMP decoding\n",
    "    #The above is the section wise probabilities. I need to convert these to bitwise probabilities. \n",
    "    # Feed the bitwise probabilities into the LDPC decoder\n",
    "    \n",
    "    # Get the output of the LDPC decoder and see if there has been any improvement in error correcting performance. \n",
    "    # Note that for now I am just applying an LDPC code to the entire block. \n",
    "    \n",
    "    #print(bitwise_posterior(β, L, M))\n",
    "    \n",
    "    # Convert decoded beta back to a message\n",
    "    rx_message = []\n",
    "    for l in range(L):\n",
    "        idx = np.argmax(β[l*M:(l+1)*M])\n",
    "        rx_message.append(idx)\n",
    "    \n",
    "    # Compute fraction of sections decoded correctly\n",
    "    correct = np.sum(np.array(rx_message) == np.array(tx_message)) / L\n",
    "    \n",
    "    # Compute BER note: np.sum will be deprecated soon, so look up alternative if this code stops working. \n",
    "    # DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.from_iter(generator)) or the python sum builtin instead.\n",
    "    # If this function starts acting weird, look into the above. Or when I transfer this function to my proper code, try to fix this. \n",
    "    ber = np.sum(bin(a^b).count('1')\n",
    "                 for (a, b) in zip(tx_message, rx_message))/(L*np.log2(M))\n",
    "    \n",
    "    # Compute Eb/N0\n",
    "    EbN0 = 1/(2*R) * (P/σ_n**2)\n",
    "    \n",
    "    return ber\n",
    "    \n",
    "    \"\"\"return {\n",
    "        \"L\": L, \"M\": M, \"sigma_n\": σ_n, \"P\": P, \"R\": R, \"T\": T,\n",
    "        \"snr\": snr, \"C\": C, \"n\": n, \"fc\": correct, \"R_PA\": R_PA,\n",
    "        \"ber\": ber, \"EbN0\": EbN0, \"ser\": 1-correct\n",
    "    }\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
